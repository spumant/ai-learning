{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import brier_score_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class_1 = 500\n",
    "class_2 = 500  #两个类别分别设定500个样本\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]]  #设定两个类别的中心\n",
    "clusters_std = [0.5, 0.5]  #设定两个类别的方差\n",
    "X, y = make_blobs(n_samples=[class_1, class_2],\n",
    "                  centers=centers,\n",
    "                  cluster_std=clusters_std,\n",
    "                  random_state=0, shuffle=False)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y\n",
    "                                                , test_size=0.3\n",
    "                                                , random_state=420)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#先归一化，保证输入多项式朴素贝叶斯的特征矩阵中不带有负数\n",
    "mms = MinMaxScaler().fit(Xtrain)\n",
    "Xtrain_ = mms.transform(Xtrain)\n",
    "Xtest_ = mms.transform(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "mnb = MultinomialNB().fit(Xtrain_, Ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.69029411, -0.69600841])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重要属性：调用根据数据获取的，每个标签类的对数先验概率log(P(Y))\n",
    "#由于概率永远是在[0,1]之间，因此对数先验概率返回的永远是负值\n",
    "mnb.class_log_prior_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(Ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49857142857142855"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ytrain == 1).sum() / Ytrain.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(2,)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_log_prior_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.50142857, 0.49857143])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以使用np.exp来查看真正的概率值\n",
    "np.exp(mnb.class_log_prior_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.76164788, -0.62903951],\n       [-0.72500918, -0.6622691 ]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重要属性：返回一个固定标签类别下的每个特征的对数概率log(P(Xi|y))\n",
    "mnb.feature_log_prob_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(2, 2)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.feature_log_prob_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([351., 349.])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重要属性：在fit时每个标签类别下包含的样本数。当fit接口中的sample_weight被设置时，该接口返回的值也会受到加权的影响\n",
    "mnb.class_count_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(2,)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_count_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#一些传统的接口\n",
    "mnb.predict(Xtest_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.49847128, 0.50152872],\n       [0.50065987, 0.49934013],\n       [0.50122363, 0.49877637],\n       [0.50183745, 0.49816255],\n       [0.50146433, 0.49853567],\n       [0.50153147, 0.49846853],\n       [0.50204549, 0.49795451],\n       [0.50033124, 0.49966876],\n       [0.50105254, 0.49894746],\n       [0.50182815, 0.49817185],\n       [0.50270707, 0.49729293],\n       [0.50133396, 0.49866604],\n       [0.49820896, 0.50179104],\n       [0.50342829, 0.49657171],\n       [0.50099022, 0.49900978],\n       [0.49974388, 0.50025612],\n       [0.50423879, 0.49576121],\n       [0.50449207, 0.49550793],\n       [0.49818224, 0.50181776],\n       [0.50245485, 0.49754515],\n       [0.50393627, 0.49606373],\n       [0.50193571, 0.49806429],\n       [0.49996152, 0.50003848],\n       [0.50460038, 0.49539962],\n       [0.50261175, 0.49738825],\n       [0.50140163, 0.49859837],\n       [0.50332522, 0.49667478],\n       [0.50122253, 0.49877747],\n       [0.50409939, 0.49590061],\n       [0.49998717, 0.50001283],\n       [0.50179417, 0.49820583],\n       [0.5000057 , 0.4999943 ],\n       [0.50190643, 0.49809357],\n       [0.50022071, 0.49977929],\n       [0.50097776, 0.49902224],\n       [0.50305244, 0.49694756],\n       [0.50109969, 0.49890031],\n       [0.50159754, 0.49840246],\n       [0.50166181, 0.49833819],\n       [0.5013594 , 0.4986406 ],\n       [0.50138322, 0.49861678],\n       [0.50174823, 0.49825177],\n       [0.50346533, 0.49653467],\n       [0.49918461, 0.50081539],\n       [0.50097953, 0.49902047],\n       [0.50178893, 0.49821107],\n       [0.49990491, 0.50009509],\n       [0.50202801, 0.49797199],\n       [0.50176739, 0.49823261],\n       [0.50254336, 0.49745664],\n       [0.50116963, 0.49883037],\n       [0.49920141, 0.50079859],\n       [0.49944211, 0.50055789],\n       [0.50031645, 0.49968355],\n       [0.50153599, 0.49846401],\n       [0.50352461, 0.49647539],\n       [0.50049178, 0.49950822],\n       [0.49983178, 0.50016822],\n       [0.50289574, 0.49710426],\n       [0.50193747, 0.49806253],\n       [0.49961192, 0.50038808],\n       [0.50198825, 0.49801175],\n       [0.50289658, 0.49710342],\n       [0.50218643, 0.49781357],\n       [0.49888163, 0.50111837],\n       [0.49920224, 0.50079776],\n       [0.50151585, 0.49848415],\n       [0.50230998, 0.49769002],\n       [0.50400072, 0.49599928],\n       [0.50138781, 0.49861219],\n       [0.50001327, 0.49998673],\n       [0.49982061, 0.50017939],\n       [0.50133343, 0.49866657],\n       [0.503153  , 0.496847  ],\n       [0.50180689, 0.49819311],\n       [0.50141445, 0.49858555],\n       [0.50248588, 0.49751412],\n       [0.50308391, 0.49691609],\n       [0.50024574, 0.49975426],\n       [0.50173534, 0.49826466],\n       [0.50018764, 0.49981236],\n       [0.50171743, 0.49828257],\n       [0.501695  , 0.498305  ],\n       [0.50357487, 0.49642513],\n       [0.50245246, 0.49754754],\n       [0.50233437, 0.49766563],\n       [0.50190721, 0.49809279],\n       [0.49839991, 0.50160009],\n       [0.50221084, 0.49778916],\n       [0.5012638 , 0.4987362 ],\n       [0.50199765, 0.49800235],\n       [0.50100067, 0.49899933],\n       [0.50122519, 0.49877481],\n       [0.50358523, 0.49641477],\n       [0.50353492, 0.49646508],\n       [0.50060048, 0.49939952],\n       [0.50261115, 0.49738885],\n       [0.50170128, 0.49829872],\n       [0.50084485, 0.49915515],\n       [0.49977894, 0.50022106],\n       [0.50134207, 0.49865793],\n       [0.49967049, 0.50032951],\n       [0.50394134, 0.49605866],\n       [0.50143828, 0.49856172],\n       [0.50356078, 0.49643922],\n       [0.50332876, 0.49667124],\n       [0.50095206, 0.49904794],\n       [0.50220001, 0.49779999],\n       [0.50256184, 0.49743816],\n       [0.50166902, 0.49833098],\n       [0.50254134, 0.49745866],\n       [0.5004789 , 0.4995211 ],\n       [0.50302788, 0.49697212],\n       [0.50052704, 0.49947296],\n       [0.50219724, 0.49780276],\n       [0.50026189, 0.49973811],\n       [0.50095584, 0.49904416],\n       [0.50206864, 0.49793136],\n       [0.50010878, 0.49989122],\n       [0.50109718, 0.49890282],\n       [0.50162885, 0.49837115],\n       [0.50020595, 0.49979405],\n       [0.50067955, 0.49932045],\n       [0.50280886, 0.49719114],\n       [0.50237353, 0.49762647],\n       [0.50222485, 0.49777515],\n       [0.5001119 , 0.4998881 ],\n       [0.50112275, 0.49887725],\n       [0.50362029, 0.49637971],\n       [0.50054287, 0.49945713],\n       [0.50070066, 0.49929934],\n       [0.50174149, 0.49825851],\n       [0.50190098, 0.49809902],\n       [0.5007135 , 0.4992865 ],\n       [0.50207309, 0.49792691],\n       [0.50270744, 0.49729256],\n       [0.50050176, 0.49949824],\n       [0.50142338, 0.49857662],\n       [0.50099023, 0.49900977],\n       [0.50084396, 0.49915604],\n       [0.50368091, 0.49631909],\n       [0.50272862, 0.49727138],\n       [0.50132287, 0.49867713],\n       [0.50401085, 0.49598915],\n       [0.50227543, 0.49772457],\n       [0.50117773, 0.49882227],\n       [0.50165111, 0.49834889],\n       [0.49957088, 0.50042912],\n       [0.50317179, 0.49682821],\n       [0.50098188, 0.49901812],\n       [0.5023283 , 0.4976717 ],\n       [0.50104249, 0.49895751],\n       [0.50104179, 0.49895821],\n       [0.501309  , 0.498691  ],\n       [0.50216322, 0.49783678],\n       [0.50110205, 0.49889795],\n       [0.50257045, 0.49742955],\n       [0.5013388 , 0.4986612 ],\n       [0.50053838, 0.49946162],\n       [0.50120029, 0.49879971],\n       [0.50127632, 0.49872368],\n       [0.50183619, 0.49816381],\n       [0.50009396, 0.49990604],\n       [0.50128105, 0.49871895],\n       [0.50158456, 0.49841544],\n       [0.50190347, 0.49809653],\n       [0.50228193, 0.49771807],\n       [0.50242186, 0.49757814],\n       [0.50201385, 0.49798615],\n       [0.50201075, 0.49798925],\n       [0.5007775 , 0.4992225 ],\n       [0.50240731, 0.49759269],\n       [0.49865226, 0.50134774],\n       [0.50451121, 0.49548879],\n       [0.50254794, 0.49745206],\n       [0.5039106 , 0.4960894 ],\n       [0.50200714, 0.49799286],\n       [0.50227154, 0.49772846],\n       [0.50115683, 0.49884317],\n       [0.50254911, 0.49745089],\n       [0.50062667, 0.49937333],\n       [0.50324846, 0.49675154],\n       [0.50165038, 0.49834962],\n       [0.50200129, 0.49799871],\n       [0.50034533, 0.49965467],\n       [0.50051902, 0.49948098],\n       [0.50029115, 0.49970885],\n       [0.50209651, 0.49790349],\n       [0.50240236, 0.49759764],\n       [0.50092696, 0.49907304],\n       [0.50250997, 0.49749003],\n       [0.4985069 , 0.5014931 ],\n       [0.4994373 , 0.5005627 ],\n       [0.5024844 , 0.4975156 ],\n       [0.50120384, 0.49879616],\n       [0.49970062, 0.50029938],\n       [0.50154039, 0.49845961],\n       [0.50257601, 0.49742399],\n       [0.5015003 , 0.4984997 ],\n       [0.50034533, 0.49965467],\n       [0.5020367 , 0.4979633 ],\n       [0.5022038 , 0.4977962 ],\n       [0.50057621, 0.49942379],\n       [0.50128065, 0.49871935],\n       [0.50042842, 0.49957158],\n       [0.50330239, 0.49669761],\n       [0.50128544, 0.49871456],\n       [0.50196417, 0.49803583],\n       [0.50194098, 0.49805902],\n       [0.50115364, 0.49884636],\n       [0.50299407, 0.49700593],\n       [0.50130317, 0.49869683],\n       [0.50375311, 0.49624689],\n       [0.50121088, 0.49878912],\n       [0.50232441, 0.49767559],\n       [0.50272548, 0.49727452],\n       [0.50001357, 0.49998643],\n       [0.50093936, 0.49906064],\n       [0.50208529, 0.49791471],\n       [0.50137482, 0.49862518],\n       [0.50080493, 0.49919507],\n       [0.50332574, 0.49667426],\n       [0.50302616, 0.49697384],\n       [0.50196237, 0.49803763],\n       [0.5023057 , 0.4976943 ],\n       [0.5006412 , 0.4993588 ],\n       [0.50224065, 0.49775935],\n       [0.5010883 , 0.4989117 ],\n       [0.50133566, 0.49866434],\n       [0.50233576, 0.49766424],\n       [0.50184149, 0.49815851],\n       [0.50098641, 0.49901359],\n       [0.5019006 , 0.4980994 ],\n       [0.50107183, 0.49892817],\n       [0.50143271, 0.49856729],\n       [0.50203595, 0.49796405],\n       [0.5026515 , 0.4973485 ],\n       [0.50377703, 0.49622297],\n       [0.49893439, 0.50106561],\n       [0.50339275, 0.49660725],\n       [0.50152766, 0.49847234],\n       [0.50158634, 0.49841366],\n       [0.50000096, 0.49999904],\n       [0.50045491, 0.49954509],\n       [0.50208306, 0.49791694],\n       [0.50352855, 0.49647145],\n       [0.50237312, 0.49762688],\n       [0.49928464, 0.50071536],\n       [0.50297955, 0.49702045],\n       [0.50170373, 0.49829627],\n       [0.50143102, 0.49856898],\n       [0.50330941, 0.49669059],\n       [0.50211473, 0.49788527],\n       [0.50202076, 0.49797924],\n       [0.50051225, 0.49948775],\n       [0.50112964, 0.49887036],\n       [0.50185392, 0.49814608],\n       [0.49966058, 0.50033942],\n       [0.50075293, 0.49924707],\n       [0.50071296, 0.49928704],\n       [0.49923395, 0.50076605],\n       [0.50080148, 0.49919852],\n       [0.49827919, 0.50172081],\n       [0.50168248, 0.49831752],\n       [0.49995601, 0.50004399],\n       [0.5014818 , 0.4985182 ],\n       [0.5008324 , 0.4991676 ],\n       [0.50225201, 0.49774799],\n       [0.50041346, 0.49958654],\n       [0.50008176, 0.49991824],\n       [0.50275251, 0.49724749],\n       [0.5013088 , 0.4986912 ],\n       [0.50199637, 0.49800363],\n       [0.50250964, 0.49749036],\n       [0.50279177, 0.49720823],\n       [0.50085703, 0.49914297],\n       [0.50363226, 0.49636774],\n       [0.50075518, 0.49924482],\n       [0.50160237, 0.49839763],\n       [0.50200633, 0.49799367],\n       [0.50294549, 0.49705451],\n       [0.50134492, 0.49865508],\n       [0.50113355, 0.49886645],\n       [0.5011625 , 0.4988375 ],\n       [0.50086075, 0.49913925],\n       [0.50223575, 0.49776425],\n       [0.50032738, 0.49967262],\n       [0.50110359, 0.49889641],\n       [0.50256978, 0.49743022],\n       [0.49850301, 0.50149699],\n       [0.5031758 , 0.4968242 ],\n       [0.50058575, 0.49941425],\n       [0.5004442 , 0.4995558 ],\n       [0.50093672, 0.49906328],\n       [0.50332508, 0.49667492],\n       [0.50399354, 0.49600646],\n       [0.50351518, 0.49648482],\n       [0.50156107, 0.49843893],\n       [0.50078711, 0.49921289],\n       [0.50197128, 0.49802872]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(Xtest_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5433333333333333"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(Xtest_,Ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2497782841254602"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,mnb.predict_proba(Xtest_)[:,1],pos_label=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#来试试看把Xtiain转换成分类型数据吧\n",
    "#注意我们的Xtrain没有经过归一化，因为做哑变量之后自然所有的数据就不会又负数了\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbs = KBinsDiscretizer(n_bins=10, encode='onehot').fit(Xtrain)\n",
    "Xtrain_ = kbs.transform(Xtrain)\n",
    "Xtest_ = kbs.transform(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "mnb = MultinomialNB().fit(Xtrain_, Ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9966666666666667"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(Xtest_,Ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0014593932778211862"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,mnb.predict_proba(Xtest_)[:,1],pos_label=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#普通来说我们应该使用二值化的类sklearn.preprocessing.Binarizer来将特征一个个二值化\n",
    "#然而这样效率过低，因此我们选择归一化之后直接设置一个阈值\n",
    "mms = MinMaxScaler().fit(Xtrain)\n",
    "Xtrain_ = mms.transform(Xtrain)\n",
    "Xtest_ = mms.transform(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#不设置二值化\n",
    "bnl_ = BernoulliNB().fit(Xtrain_, Ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49666666666666665"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnl_.score(Xtest_,Ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.25000009482193225"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,bnl_.predict_proba(Xtest_)[:,1],pos_label=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#设置二值化阈值为0.5\n",
    "bnl = BernoulliNB(binarize=0.5).fit(Xtrain_, Ytrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9833333333333333"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnl.score(Xtest_,Ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.010405875827339534"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,bnl.predict_proba(Xtest_)[:,1],pos_label=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}